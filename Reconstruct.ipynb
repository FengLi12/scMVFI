{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From F:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.reset_default_graph()\n",
    "tf.disable_v2_behavior()\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_block_from_data(data, batch_size):\n",
    "    start_index = np.random.randint(0, len(data) - batch_size)\n",
    "    return data[start_index:(start_index + batch_size)]\n",
    "class Autoencoder(object):\n",
    "\n",
    "    def __init__(self, n_input, n_hidden1,n_hidden2,n_hidden3, transfer_function=tf.nn.softplus, optimizer = tf.compat.v1.train.AdamOptimizer()):\n",
    "        self.n_input = n_input\n",
    "        self.n_hidden1 = n_hidden1\n",
    "        self.n_hidden2 = n_hidden2\n",
    "        self.n_hidden3 = n_hidden3\n",
    "        self.transfer = transfer_function\n",
    "\n",
    "        network_weights = self._initialize_weights()\n",
    "        self.weights = network_weights\n",
    "\n",
    "        # model\n",
    "        tf.compat.v1.disable_eager_execution()\n",
    "        self.x = tf.placeholder(tf.float32, [None, self.n_input])\n",
    "        self.hidden1 = self.transfer(tf.add(tf.matmul(self.x, self.weights['w1']), self.weights['b1']))\n",
    "        self.hidden2 = self.transfer(tf.add(tf.matmul(self.hidden1, self.weights['w2']), self.weights['b2']))\n",
    "        self.hidden3 = self.transfer(tf.add(tf.matmul(self.hidden2, self.weights['w3']), self.weights['b3']))\n",
    "        self.reconstruction = tf.add(tf.matmul(self.hidden3, self.weights['w4']), self.weights['b4'])\n",
    "\n",
    "        # cost\n",
    "        self.cost = 0.5 * tf.reduce_sum(tf.pow(tf.subtract(self.reconstruction, self.x), 2.0))\n",
    "        self.optimizer = optimizer.minimize(self.cost)\n",
    "\n",
    "        init = tf.global_variables_initializer()\n",
    "        self.sess = tf.Session()\n",
    "        self.sess.run(init)\n",
    "\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        all_weights = dict()\n",
    "        all_weights['w1'] = tf.get_variable(\"w1\", shape=[self.n_input, self.n_hidden1],\n",
    "            initializer=tf.glorot_uniform_initializer())\n",
    "        all_weights['b1'] = tf.Variable(tf.zeros([self.n_hidden1], dtype=tf.float32))\n",
    "        all_weights['w2'] = tf.get_variable(\"w2\", shape=[self.n_hidden1, self.n_hidden2],\n",
    "            initializer=tf.glorot_uniform_initializer())\n",
    "        all_weights['b2'] = tf.Variable(tf.zeros([self.n_hidden2], dtype=tf.float32))\n",
    "        all_weights['w3'] = tf.get_variable(\"w3\", shape=[self.n_hidden2, self.n_hidden3],\n",
    "            initializer=tf.glorot_uniform_initializer())\n",
    "        all_weights['b3'] = tf.Variable(tf.zeros([self.n_hidden3], dtype=tf.float32))\n",
    "        all_weights['w4'] = tf.Variable(tf.zeros([self.n_hidden3, self.n_input], dtype=tf.float32))\n",
    "        all_weights['b4'] = tf.Variable(tf.zeros([self.n_input], dtype=tf.float32))\n",
    "        return all_weights\n",
    "\n",
    "    def partial_fit(self, X):\n",
    "        cost, opt = self.sess.run((self.cost, self.optimizer), feed_dict={self.x: X})\n",
    "        return cost\n",
    "\n",
    "    def calc_total_cost(self, X):\n",
    "        return self.sess.run(self.cost, feed_dict = {self.x: X})\n",
    "\n",
    "    def transform(self, X):\n",
    "        return self.sess.run(self.hidden2, feed_dict={self.x: X})\n",
    "\n",
    "    def generate(self, hidden = None):\n",
    "        if hidden is None:\n",
    "            hidden = self.sess.run(tf.random_normal([1, self.n_hidden]))\n",
    "        return self.sess.run(self.reconstruction, feed_dict={self.hidden: hidden})\n",
    "\n",
    "    def reconstruct(self, X):\n",
    "        return self.sess.run(self.reconstruction, feed_dict={self.x: X})\n",
    "\n",
    "    def getWeights(self):\n",
    "        return self.sess.run(self.weights['w1'],self.weights['w2'],self.weights['w3'],self.weights['w4'])\n",
    "\n",
    "    def getBiases(self):\n",
    "        return self.sess.run(self.weights['b1'],self.weights['b2'],self.weights['b3'],self.weights['b4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autorunner(data_name, epochs, h1, h2, args_name):\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "    input_path = data_name +\".csv\"\n",
    "    X = pd.read_csv(input_path, header=None)\n",
    "    #X = X.drop(0, axis=1)\n",
    "    X = np.array(X)\n",
    "    X = X.transpose()\n",
    "    batch_size = X.shape[0]-1\n",
    "    num = X.shape[1]\n",
    "    file_path = args_name +\".csv\"\n",
    "    \n",
    "    n_samples,_ = np.shape(X)\n",
    "\n",
    "    training_epochs = epochs\n",
    "    display_step = 1\n",
    "\n",
    "    autoencoder = Autoencoder(\n",
    "        n_input = num,\n",
    "        n_hidden1 = h1,\n",
    "        n_hidden2 = h2,\n",
    "        n_hidden3 = h1,\n",
    "        transfer_function=tf.nn.softplus,\n",
    "        optimizer=tf.train.AdamOptimizer(learning_rate=0.001))\n",
    "    \n",
    "    \n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0\n",
    "        total_batch = int(n_samples / batch_size)\n",
    "        for i in range(total_batch):\n",
    "            batch_xs = get_random_block_from_data(X, batch_size)\n",
    "            cost = autoencoder.partial_fit(batch_xs)\n",
    "            avg_cost += cost / n_samples * batch_size\n",
    "        if epoch % display_step == 0:\n",
    "            print(\"Epoch:\", '%d,' % (epoch + 1),\n",
    "                  \"Cost:\", \"{:.9f}\".format(avg_cost))    \n",
    "\n",
    "    print(\"Total cost: \" + str(autoencoder.calc_total_cost(X)))\n",
    "    X_test_transform=autoencoder.transform(X)\n",
    "    X_test_reconstruct=autoencoder.reconstruct(X)\n",
    "    \n",
    "    \n",
    "    with open(file_path, 'w', newline='') as fout:\n",
    "        writer = csv.writer(fout, delimiter=',')\n",
    "        for i in X_test_reconstruct:\n",
    "            writer.writerow(i)\n",
    "            \n",
    "    return X_test_reconstruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
